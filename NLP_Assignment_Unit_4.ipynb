{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_Unit_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7DDp1PHrdR9"
      },
      "source": [
        "#  Brown corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwBo0MyvsQcm"
      },
      "source": [
        "Question: Write a program in Python to find the occurrence of articles / determiners in brown corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tjm57sI0Mgd"
      },
      "source": [
        "**Installing NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scX-Uua_xIv-",
        "outputId": "cf032aef-2c22-4665-f0b8-2061e403d1cf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bFDH0blzoPT"
      },
      "source": [
        "**Occurence of determiners**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo44_XxkwhvS",
        "outputId": "2861cc80-1545-49a3-9a03-93b6f88b257d"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "cfd = nltk.ConditionalFreqDist((genre, word) for genre in brown.categories() for word in brown.words(categories=genre))\n",
        "\n",
        "genres = ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
        "determiners = ['he','she','it','they','can', 'could', 'may', 'might', 'must', 'will']\n",
        "cfd.tabulate(conditions=genres, samples=determiners)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   he   she    it  they   can could   may might  must  will \n",
            "      adventure   761   240   492   206    46   151     5    58    27    50 \n",
            " belles_lettres  1174   178  1059   488   246   213   207   113   170   236 \n",
            "      editorial   268    41   386   148   121    56    74    39    53   233 \n",
            "        fiction   813   280   458   230    37   166     8    44    55    52 \n",
            "     government   120     0   218    92   117    38   153    13   102   244 \n",
            "        hobbies   155    21   476   177   268    58   131    22    83   264 \n",
            "          humor   146    58   162    70    16    30     8     8     9    13 \n",
            "        learned   328    54   856   338   365   159   324   128   202   340 \n",
            "           lore   541   232   566   303   170   141   165    49    96   175 \n",
            "        mystery   670   219   515   106    42   141    13    57    30    20 \n",
            "           news   451    42   363   205    93    86    66    38    50   389 \n",
            "       religion   137    10   264   115    82    59    78    12    54    71 \n",
            "        reviews   161    42   206    74    45    40    45    26    19    58 \n",
            "        romance   702   496   573   168    74   193    11    51    45    43 \n",
            "science_fiction   139    36   129    53    16    49     4    12     8    16 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC1yxfDJ0Sfm"
      },
      "source": [
        "**Occurence of articles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Qj3i3vxFcu",
        "outputId": "fa4043bd-21b0-4d3b-969b-9fead11ce546"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "print(brown.categories())\n",
        "\n",
        "  \t\n",
        "cfd = nltk.ConditionalFreqDist((genre, word) for genre in brown.categories() for word in brown.words(categories=genre))\n",
        "\n",
        "genres = ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
        "articles = ['a','an','the']\n",
        "cfd.tabulate(conditions=genres, samples=articles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
            "                    a    an   the \n",
            "      adventure  1354   159  3370 \n",
            " belles_lettres  3308   583  9726 \n",
            "      editorial  1095   184  3508 \n",
            "        fiction  1281   156  3423 \n",
            "     government   867   208  4143 \n",
            "        hobbies  1737   226  4300 \n",
            "          humor   505    75   930 \n",
            "        learned  3215   695 11079 \n",
            "           lore  2304   364  6328 \n",
            "        mystery  1136   125  2573 \n",
            "           news  1993   300  5580 \n",
            "       religion   655   119  2295 \n",
            "        reviews   874   163  2048 \n",
            "        romance  1335   152  2758 \n",
            "science_fiction   222    33   652 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRZCbll8rmTO"
      },
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLkZWoILsV8-"
      },
      "source": [
        "Questions: \n",
        "\n",
        "1. Build NaiveBayes Classifier using NLTK with the training data and find the classification accuracy  of the test data. Consider any bench mark data set.\n",
        "2. List the most significant features of data set\n",
        "3. Apply supervised classification algorithms (any 5  algorithms) using SKLEARN for the same problem.\n",
        "4. Explore possibility of supervised algorithms using SPACY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6VpgzXiRGa3"
      },
      "source": [
        "**Dataset Description:**\n",
        "\n",
        "Dataset used: IMDB Dataset\n",
        "\n",
        "Dataset description: \n",
        "1. IMDB dataset having 50K movie reviews for natural\n",
        "language processing or Text analytics.\n",
        "2. Dataset is of binary sentiment classification\n",
        "3.  Total instances - 50,000\n",
        "4.  To classify the reviews as either positive or negative using either classification algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLWCtCzfcbZC",
        "outputId": "c5aa600a-3d83-49de-dbc0-4aec1a2d835d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Xkn7xlXvjg"
      },
      "source": [
        "**Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9cILDFqWPWT",
        "outputId": "9248d072-cdde-4ee1-ab47-ce95709763c6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import sklearn.model_selection\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "525lc4mUXrUC"
      },
      "source": [
        "**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RcZraoh5WVW-",
        "outputId": "5d8ebe3d-0ff6-43c3-cd79-332bdad25d1e"
      },
      "source": [
        "df_eng = pd.read_csv('/content/drive/MyDrive/data/IMDB.csv')\n",
        "df_eng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmOmDPvSXn7e"
      },
      "source": [
        "**Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYIJVHNNUUin"
      },
      "source": [
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    # Removing spaces and converting text into lowercase\n",
        "    return text.strip().lower()\n",
        "\n",
        "def remove_punctuations(txt):\n",
        "  text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "  return text_nopunc\n",
        "\n",
        "df_eng['review']=df_eng['review'].apply(lambda x: remove_punctuations(x))\n",
        "\n",
        "df_eng['review']=df_eng['review'].apply(lambda x: clean_text(x))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCY6sb4pX1-d"
      },
      "source": [
        "**Feature extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cChsTffQXhSM"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Encoder = LabelEncoder()\n",
        "df_eng['sentiment']=Encoder.fit_transform(df_eng['sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkEMyU-XUWIy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_eng['review'], df_eng['sentiment'], test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5mGZM15YZrH"
      },
      "source": [
        "tfidf = TfidfVectorizer(max_features=20000)\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_test = tfidf.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DiCyGnldkaw"
      },
      "source": [
        "**Naive Bayes Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nKXeUeiYg2z",
        "outputId": "abaf85d3-5fde-4d3a-b115-a8887c92b015"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "y_pred = naive_bayes.predict(X_test)\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred)) \n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.8615333333333334\n",
            "Confusion Matrix: [[6485 1003]\n",
            " [1074 6438]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86      7488\n",
            "           1       0.87      0.86      0.86      7512\n",
            "\n",
            "    accuracy                           0.86     15000\n",
            "   macro avg       0.86      0.86      0.86     15000\n",
            "weighted avg       0.86      0.86      0.86     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whh0NJTteyoW"
      },
      "source": [
        "**Classifier 1: MLP Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXs5dg_TexzP",
        "outputId": "c7a5ae56-95aa-4f1d-99c5-e248b2622733"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=10, alpha=0.0001,solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print('MLPClassifier')\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred)) \n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.69300070\n",
            "Iteration 2, loss = 0.69249483\n",
            "Iteration 3, loss = 0.69187788\n",
            "Iteration 4, loss = 0.69119441\n",
            "Iteration 5, loss = 0.69050472\n",
            "Iteration 6, loss = 0.68977390\n",
            "Iteration 7, loss = 0.68899275\n",
            "Iteration 8, loss = 0.68809264\n",
            "Iteration 9, loss = 0.68710589\n",
            "Iteration 10, loss = 0.68605717\n",
            "Iteration 11, loss = 0.68492359\n",
            "Iteration 12, loss = 0.68368507\n",
            "Iteration 13, loss = 0.68237763\n",
            "Iteration 14, loss = 0.68088815\n",
            "Iteration 15, loss = 0.67921352\n",
            "Iteration 16, loss = 0.67739863\n",
            "Iteration 17, loss = 0.67541404\n",
            "Iteration 18, loss = 0.67314292\n",
            "Iteration 19, loss = 0.67066106\n",
            "Iteration 20, loss = 0.66785268\n",
            "Iteration 21, loss = 0.66465688\n",
            "Iteration 22, loss = 0.66110032\n",
            "Iteration 23, loss = 0.65709077\n",
            "Iteration 24, loss = 0.65255240\n",
            "Iteration 25, loss = 0.64742947\n",
            "Iteration 26, loss = 0.64166895\n",
            "Iteration 27, loss = 0.63518922\n",
            "Iteration 28, loss = 0.62793042\n",
            "Iteration 29, loss = 0.61980871\n",
            "Iteration 30, loss = 0.61081340\n",
            "Iteration 31, loss = 0.60095203\n",
            "Iteration 32, loss = 0.59014727\n",
            "Iteration 33, loss = 0.57847867\n",
            "Iteration 34, loss = 0.56600088\n",
            "Iteration 35, loss = 0.55271123\n",
            "Iteration 36, loss = 0.53898581\n",
            "Iteration 37, loss = 0.52480232\n",
            "Iteration 38, loss = 0.51022882\n",
            "Iteration 39, loss = 0.49580631\n",
            "Iteration 40, loss = 0.48123342\n",
            "Iteration 41, loss = 0.46690384\n",
            "Iteration 42, loss = 0.45288484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLPClassifier\n",
            "Accuracy score: 0.8344666666666667\n",
            "Confusion Matrix: [[6186 1302]\n",
            " [1181 6331]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83      7488\n",
            "           1       0.83      0.84      0.84      7512\n",
            "\n",
            "    accuracy                           0.83     15000\n",
            "   macro avg       0.83      0.83      0.83     15000\n",
            "weighted avg       0.83      0.83      0.83     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiQo1bhffQPc"
      },
      "source": [
        "**Classifier 2 : Support Vector Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvgLu928fC2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527fb6f2-0c78-4408-f819-ca29cc2146ba"
      },
      "source": [
        "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
        "clf = SVC(kernel='linear') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print('SVC')\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred)) \n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC\n",
            "Accuracy score: 0.8968\n",
            "Confusion Matrix: [[6575  797]\n",
            " [ 751 6877]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.89      7372\n",
            "           1       0.90      0.90      0.90      7628\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzRuQ5TffYJC"
      },
      "source": [
        "**Classifier 3 : Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl7pUpA4fmOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8546a2a7-073d-4ca4-d8a6-c29ea531a92b"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print('DecisionTreeClassifier')\n",
        "\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred)) \n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier\n",
            "Accuracy score: 0.7123333333333334\n",
            "Confusion Matrix: [[5251 2121]\n",
            " [2194 5434]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71      7372\n",
            "           1       0.72      0.71      0.72      7628\n",
            "\n",
            "    accuracy                           0.71     15000\n",
            "   macro avg       0.71      0.71      0.71     15000\n",
            "weighted avg       0.71      0.71      0.71     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4wf-ynagBGK"
      },
      "source": [
        "**Classifier 4 : KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT0EXcuuf09W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39bfb426-c068-4a6f-e268-83bd57f04c57"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf=KNeighborsClassifier(3)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print('KNeighborsClassifier')\n",
        "\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred)) \n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier\n",
            "Accuracy score: 0.7413333333333333\n",
            "Confusion Matrix: [[5149 2223]\n",
            " [1657 5971]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.70      0.73      7372\n",
            "           1       0.73      0.78      0.75      7628\n",
            "\n",
            "    accuracy                           0.74     15000\n",
            "   macro avg       0.74      0.74      0.74     15000\n",
            "weighted avg       0.74      0.74      0.74     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00-MD78AgFWS"
      },
      "source": [
        "**Classifier 5: Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBcpNRdWgL37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80190d8-661a-4951-ef2a-43f13354269a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier \n",
        "clf= RandomForestClassifier(max_depth=6, n_estimators=12, max_features=5)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print('RandomForestClassifier')\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred)) \n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier\n",
            "Accuracy score: 0.5221333333333333\n",
            "Confusion Matrix: [[6880  492]\n",
            " [6676  952]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.93      0.66      7372\n",
            "           1       0.66      0.12      0.21      7628\n",
            "\n",
            "    accuracy                           0.52     15000\n",
            "   macro avg       0.58      0.53      0.43     15000\n",
            "weighted avg       0.58      0.52      0.43     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h0nqWQXgTEX"
      },
      "source": [
        "**Classifier 6: AdaBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec2F9lBSrTna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716c70b5-8f72-44a5-f8ea-bd34cf2859fc"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf= AdaBoostClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print('AdaBoostClassifier')\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred)) \n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier\n",
            "Accuracy score: 0.7966\n",
            "Confusion Matrix: [[5623 1749]\n",
            " [1302 6326]]\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.76      0.79      7372\n",
            "           1       0.78      0.83      0.81      7628\n",
            "\n",
            "    accuracy                           0.80     15000\n",
            "   macro avg       0.80      0.80      0.80     15000\n",
            "weighted avg       0.80      0.80      0.80     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0fgJvcN7iZR"
      },
      "source": [
        "# Spacy Classifier : Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL9CrixkzqR0",
        "outputId": "503af7e6-419e-47a6-c02d-6e9f37efbeaa"
      },
      "source": [
        "import spacy\n",
        "spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7fb2d2c65e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HrMwUKU13Oh_",
        "outputId": "637a8fcd-66ea-44cb-e9ab-e59c1cce57d9"
      },
      "source": [
        "# Import pandas & read csv file\n",
        "import pandas as pd\n",
        "reviews=pd.read_csv(\"https://raw.githubusercontent.com/hanzhang0420/Women-Clothing-E-commerce/master/Womens%20Clothing%20E-Commerce%20Reviews.csv\")\n",
        "\n",
        "# Extract desired columns and view the dataframe \n",
        "df_amazon = reviews[['Review Text','Recommended IND']].dropna()\n",
        "df_amazon.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Recommended IND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I love tracy reese dresses, but this one is no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I aded this in my basket at hte last mintue to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I ordered this in carbon for store pick up, an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I love this dress. i usually get an xs but it ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I'm 5\"5' and 125 lbs. i ordered the s petite t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Review Text  Recommended IND\n",
              "0  Absolutely wonderful - silky and sexy and comf...                1\n",
              "1  Love this dress!  it's sooo pretty.  i happene...                1\n",
              "2  I had such high hopes for this dress and reall...                0\n",
              "3  I love, love, love this jumpsuit. it's fun, fl...                1\n",
              "4  This shirt is very flattering to all due to th...                1\n",
              "5  I love tracy reese dresses, but this one is no...                0\n",
              "6  I aded this in my basket at hte last mintue to...                1\n",
              "7  I ordered this in carbon for store pick up, an...                1\n",
              "8  I love this dress. i usually get an xs but it ...                1\n",
              "9  I'm 5\"5' and 125 lbs. i ordered the s petite t...                1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icnj3L2I-I6v"
      },
      "source": [
        "import string\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "# Create our list of punchuationmarks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stop words\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vector\n",
        "parser = English()\n",
        "\n",
        "# Creating our tokenzer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    \"\"\"This function will accepts a sentence as input and processes the sentence into tokens, performing lemmatization, \n",
        "    lowercasing, removing stop words and punctuations.\"\"\"\n",
        "    \n",
        "    # Creating our token object which is used to create documents with linguistic annotations\n",
        "    mytokens = parser(sentence)\n",
        "    \n",
        "    # lemmatizing each token and converting each token in lower case\n",
        "    # Note that spaCy uses '-PRON-' as lemma for all personal pronouns lkike me, I etc\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "    \n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations]\n",
        "    \n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ3Kakpx-Lsd"
      },
      "source": [
        "# Custom transformer using spaCy\n",
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        \"\"\"Override the transform method to clean text\"\"\"\n",
        "        return [clean_text(text) for text in X]\n",
        "    \n",
        "    def fit(self, X, y= None, **fit_params):\n",
        "        return self\n",
        "    \n",
        "    def get_params(self, deep= True):\n",
        "        return {}\n",
        "\n",
        "# Basic function to clean the text\n",
        "def clean_text(text):\n",
        "    \"\"\"Removing spaces and converting the text into lowercase\"\"\"\n",
        "    return text.strip().lower() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwZEYUfD-QdH"
      },
      "source": [
        "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range = (1,1))\n",
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W2m6deL-dak",
        "outputId": "d41f8e44-2e7e-4af2-9fd7-0ca311db1b49"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_amazon['Review Text'] # The features we want to analyse\n",
        "ylabels = df_amazon['Recommended IND'] # The labels, in this case feedback\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size = 0.3, random_state = 1)\n",
        "print(f'X_train dimension: {X_train.shape}')\n",
        "print(f'y_train dimension: {y_train.shape}')\n",
        "print(f'X_test dimension: {X_test.shape}')\n",
        "print(f'y_train dimension: {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train dimension: (15848,)\n",
            "y_train dimension: (15848,)\n",
            "X_test dimension: (6793,)\n",
            "y_train dimension: (6793,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbFdlTLn_D_5",
        "outputId": "e2fe4502-0fdc-4e0d-e4ee-123dc9a3ebfe"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline ([(\"cleaner\", predictors()),\n",
        "                 (\"vectorizer\", bow_vector),\n",
        "                 (\"classifier\", classifier)])\n",
        "\n",
        "# Model generation\n",
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner', <__main__.predictors object at 0x7fb2e4126350>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 t...\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function spacy_tokenizer at 0x7fb2e45d1a70>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-lsxgHf_JK3",
        "outputId": "5d5d544e-4b9c-4606-ddbc-449926550553"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "# Predicting with test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "# Model accuracy score\n",
        "print(f'Logistic Regression Accuracy: {metrics.accuracy_score(y_test, predicted)}')\n",
        "print(f'Logistic Regression Precision: {metrics.precision_score(y_test, predicted)}')\n",
        "print(f'Logistic Regression Recall: {metrics.recall_score(y_test, predicted)}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.8875312822022671\n",
            "Logistic Regression Precision: 0.9121517689283883\n",
            "Logistic Regression Recall: 0.9552532665115446\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}